{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import yfinance as yf\n",
    "import sys\n",
    "sys.path.append('../data_func')\n",
    "from data_helper_functions import create_study_periods,create_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/crsp_ff_adjusted.csv')\n",
    "df['RET']=pd.to_numeric(df['RET'],errors='coerce')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.dropna(subset=['RET'],inplace=True)\n",
    "#drop unamed 0 column\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobbarcelona/.pyenv/versions/3.9.16/lib/python3.9/site-packages/pandas/core/frame.py:5034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "#select returns to use\n",
    "returns='Adj_RET_Mkt'\n",
    "df=df[['date','TICKER',f'{returns}']]\n",
    "if returns!='RET':\n",
    "    #rename returns column\n",
    "    df.rename(columns={f'{returns}':'RET'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 25/29 [00:10<00:01,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached the end of the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Optional parameter target_type: 'cross_sectional_median(default)','buckets(10 buckets)','raw_returns'.\n",
    "study_periods=create_study_periods(df,n_periods=23,window_size=240,trade_size=250,train_size=750,forward_roll=250,start_date=datetime(1990,1,1),end_date=datetime(2015,12,31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=6)]: Done  17 out of  25 | elapsed:  9.9min remaining:  4.7min\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  25 | elapsed: 12.9min remaining:  3.2min\n",
      "[Parallel(n_jobs=6)]: Done  23 out of  25 | elapsed: 13.1min remaining:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done  25 out of  25 | elapsed: 14.6min finished\n"
     ]
    }
   ],
   "source": [
    "train_test_splits=create_tensors(study_periods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([259482, 240, 1]) torch.Size([259482]) torch.Size([86423, 240, 1]) torch.Size([86423])\n",
      "torch.Size([259523, 240, 1]) torch.Size([259523]) torch.Size([85610, 240, 1]) torch.Size([85610])\n",
      "torch.Size([257790, 240, 1]) torch.Size([257790]) torch.Size([86667, 240, 1]) torch.Size([86667])\n",
      "torch.Size([259178, 240, 1]) torch.Size([259178]) torch.Size([86360, 240, 1]) torch.Size([86360])\n",
      "torch.Size([259115, 240, 1]) torch.Size([259115]) torch.Size([85279, 240, 1]) torch.Size([85279])\n",
      "torch.Size([258784, 240, 1]) torch.Size([258784]) torch.Size([84181, 240, 1]) torch.Size([84181])\n",
      "torch.Size([256298, 240, 1]) torch.Size([256298]) torch.Size([86916, 240, 1]) torch.Size([86916])\n",
      "torch.Size([256854, 240, 1]) torch.Size([256854]) torch.Size([85044, 240, 1]) torch.Size([85044])\n",
      "torch.Size([256619, 240, 1]) torch.Size([256619]) torch.Size([86592, 240, 1]) torch.Size([86592])\n",
      "torch.Size([259030, 240, 1]) torch.Size([259030]) torch.Size([86542, 240, 1]) torch.Size([86542])\n",
      "torch.Size([258656, 240, 1]) torch.Size([258656]) torch.Size([86152, 240, 1]) torch.Size([86152])\n",
      "torch.Size([259764, 240, 1]) torch.Size([259764]) torch.Size([86189, 240, 1]) torch.Size([86189])\n",
      "torch.Size([259361, 240, 1]) torch.Size([259361]) torch.Size([87653, 240, 1]) torch.Size([87653])\n",
      "torch.Size([260472, 240, 1]) torch.Size([260472]) torch.Size([85248, 240, 1]) torch.Size([85248])\n",
      "torch.Size([259568, 240, 1]) torch.Size([259568]) torch.Size([85867, 240, 1]) torch.Size([85867])\n",
      "torch.Size([259246, 240, 1]) torch.Size([259246]) torch.Size([86707, 240, 1]) torch.Size([86707])\n",
      "torch.Size([258300, 240, 1]) torch.Size([258300]) torch.Size([86771, 240, 1]) torch.Size([86771])\n",
      "torch.Size([259823, 240, 1]) torch.Size([259823]) torch.Size([86215, 240, 1]) torch.Size([86215])\n",
      "torch.Size([260171, 240, 1]) torch.Size([260171]) torch.Size([86325, 240, 1]) torch.Size([86325])\n",
      "torch.Size([259789, 240, 1]) torch.Size([259789]) torch.Size([87728, 240, 1]) torch.Size([87728])\n",
      "torch.Size([260746, 240, 1]) torch.Size([260746]) torch.Size([85753, 240, 1]) torch.Size([85753])\n",
      "torch.Size([260284, 240, 1]) torch.Size([260284]) torch.Size([85279, 240, 1]) torch.Size([85279])\n",
      "torch.Size([259238, 240, 1]) torch.Size([259238]) torch.Size([87245, 240, 1]) torch.Size([87245])\n",
      "torch.Size([258755, 240, 1]) torch.Size([258755]) torch.Size([86166, 240, 1]) torch.Size([86166])\n",
      "torch.Size([259168, 240, 1]) torch.Size([259168]) torch.Size([85663, 240, 1]) torch.Size([85663])\n"
     ]
    }
   ],
   "source": [
    "#Optional code to verify tensor shapes\n",
    "# for train_data, train_labels, test_data, test_labels in train_test_splits:\n",
    "#     print(train_data.shape, train_labels.shape, test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now our prediction task is predicting a stocks returns above or below the cross section rolling median of returns. But I want to be able to reject making a prediction, (a -1 choice) when I am not confident in the prediction.\n",
    "We can train a model g(x) that rejects or acepts data to make a prediction and a model f(x) that predicts the returns. We can then combine the two models to make a prediction.\n",
    "\n",
    "If I can somehow make a stochastic transformer, and during testing reject data points that are too far from our self-attention centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Checking if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Define the LSTM Classifier model\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True, dropout=0.1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # We only want the last output of the sequence\n",
    "        return out\n",
    "\n",
    "model = LSTMClassifier(input_size=1, hidden_size=25, output_size=2).to(device)  # Move model to GPU if available\n",
    "# Loss depends on target, MAE for returns, Cross Entropy for above/below cross-sectional median. Also have selective loss in utils\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "# Parameters\n",
    "patience = 10\n",
    "n_epochs = 1000\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    for train_data, train_labels, val_data, val_labels in tqdm(train_test_splits):\n",
    "        model.train()\n",
    "\n",
    "        train_data, train_labels = train_data.to(device), train_labels.to(device)  # Move data to GPU if available\n",
    "\n",
    "        # Convert the dataset into DataLoader for batching\n",
    "        train_dataset = TensorDataset(train_data, train_labels)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "        for sequences, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "\n",
    "        val_data, val_labels = val_data.to(device), val_labels.to(device)  # Move data to GPU if available\n",
    "        \n",
    "        # Adding DataLoader for validation data\n",
    "        val_dataset = TensorDataset(val_data, val_labels)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for sequences, labels in val_loader:\n",
    "                outputs = model(sequences)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss}, Validation Loss: {val_loss}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter == patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "in_sample_long_portfolios = pd.DataFrame()\n",
    "out_of_sample_long_portfolios = pd.DataFrame()\n",
    "\n",
    "in_sample_short_portfolios = pd.DataFrame()\n",
    "out_of_sample_short_portfolios = pd.DataFrame()\n",
    "\n",
    "k = 10  # Number of top assets to select in portfolios\n",
    "\n",
    "for train_data, train_labels, val_data, val_labels in tqdm(train_test_splits):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        train_predictions = model(train_data.to(device)\n",
    "        val_predictions = model(val_data.to(device))\n",
    "\n",
    "        train_probs = torch.softmax(train_predictions, dim=1)[:, 1].cpu().numpy()\n",
    "        val_probs = torch.softmax(val_predictions, dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "    # Assuming you have a dataframe or similar structure to hold the date and TICKER information\n",
    "    train_df['predicted_prob'] = train_probs\n",
    "    val_df['predicted_prob'] = val_probs\n",
    "\n",
    "    # In-Sample Portfolio Construction\n",
    "    for date in train_df['date'].unique():\n",
    "        date_data = train_df[train_df['date'] == date].sort_values(by='predicted_prob', ascending=False)\n",
    "        \n",
    "        long_tickers = date_data.head(k)\n",
    "        short_tickers = date_data.tail(k)\n",
    "        \n",
    "        in_sample_long_portfolios = pd.concat([in_sample_long_portfolios, long_tickers])\n",
    "        in_sample_short_portfolios = pd.concat([in_sample_short_portfolios, short_tickers])\n",
    "\n",
    "    # Out-of-Sample Portfolio Construction\n",
    "    for date in val_df['date'].unique():\n",
    "        date_data = val_df[val_df['date'] == date].sort_values(by='predicted_prob', ascending=False)\n",
    "        \n",
    "        long_tickers = date_data.head(k)\n",
    "        short_tickers = date_data.tail(k)\n",
    "        \n",
    "        out_of_sample_long_portfolios = pd.concat([out_of_sample_long_portfolios, long_tickers])\n",
    "        out_of_sample_short_portfolios = pd.concat([out_of_sample_short_portfolios, short_tickers])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_long_portfolios.to_csv('../data/ltsm_results/in_sample_long_portfolios.csv')\n",
    "in_sample_short_portfolios.to_csv('../data/ltsm_results/in_sample_short_portfolios.csv')\n",
    "out_of_sample_long_portfolios.to_csv('../data/ltsm_results/out_of_sample_long_portfolios.csv')\n",
    "out_of_sample_short_portfolios.to_csv('../data/ltsm_results/out_of_sample_short_portfolios.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
